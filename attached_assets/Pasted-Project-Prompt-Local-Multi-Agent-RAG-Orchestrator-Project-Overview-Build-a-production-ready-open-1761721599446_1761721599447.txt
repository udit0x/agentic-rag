Project Prompt: Local Multi-Agent RAG Orchestrator
Project Overview
Build a production-ready, open-source RAG (Retrieval-Augmented Generation) system with multi-agent orchestration, specialized reasoning modes, and temporal awareness. The system will run locally with Azure OpenAI integration.
Core Objectives

Multi-Agent Architecture: Implement Router, Retriever, Reasoning, Simulation, and Temporal agents with LangGraph orchestration
Specialized Reasoning Modes:

Standard factual retrieval
Counterfactual simulation ("what-if" scenarios)
Temporal truth detection (outdated knowledge identification)


Production-Ready UI: ChatGPT-style interface with context panels and optional reasoning trace visualization
Local-First Design: All data stored locally, Azure OpenAI for LLM/embeddings, optional local vector DB fallback

Technical Stack
Backend

Framework: FastAPI with async/await patterns
Orchestration: LangGraph for agent workflow, LangChain LCEL for chain composition
LLM: Azure OpenAI (GPT-4o/GPT-4-Turbo)
Embeddings: text-embedding-3-large via Azure OpenAI
Vector Store: Azure Cognitive Search (primary), Chroma (local fallback)
Storage: Local filesystem (/data directory)
Configuration: python-dotenv for environment management

Frontend

Framework: Next.js 14+ (App Router)
Styling: Tailwind CSS + ShadCN UI components
Animations: Framer Motion (subtle, purposeful)
State: React Query/SWR for server state
Markdown: react-markdown with syntax highlighting
Layout: Two-pane design (chat + context panel)

Key Dependencies

LangChain, LangGraph, LangChain Community
Azure OpenAI SDK
FastAPI, uvicorn
Pydantic for validation
React Query, Zustand (if needed for client state)

Agent Architecture
1. Router Agent
Purpose: Query classification and routing
Input: User query string
Output: Classification (factual/counterfactual/temporal) + confidence
Logic:

Pattern matching for keywords ("what if", "suppose", "imagine")
Timestamp analysis from metadata
LLM-based classification for ambiguous cases

2. Retriever Agent
Purpose: Document search and ranking
Input: Query + classification context
Output: Ranked chunks with metadata (source, timestamp, confidence)
Logic:

Semantic search via embeddings
Metadata filtering (date ranges, document types)
Re-ranking for relevance

3. Reasoning Agent
Purpose: Standard factual synthesis
Input: Query + retrieved chunks
Output: Natural language answer with citations
Logic:

Summarization with source attribution
Confidence scoring
Citation formatting

4. Simulation Agent
Purpose: Counterfactual reasoning with quantitative projections
Input: Query + baseline data + simulation parameters
Output: Projected scenario with comparison to current state
Logic:

Extract numerical parameters from query
Execute Python-based calculations (safe sandbox)
Generate comparative analysis

5. Temporal Agent
Purpose: Detect knowledge evolution and conflicts
Input: Retrieved chunks with timestamps
Output: Temporal analysis highlighting changes/conflicts
Logic:

Cluster documents by date
Identify contradictions across time periods
Flag outdated information
Generate timeline summary

Development Phases
Phase 1: Foundation (Start Here)
Goal: Basic RAG pipeline with document ingestion and retrieval
Backend Tasks:

Set up FastAPI project structure with proper routing
Implement Azure OpenAI client initialization with error handling
Create document ingestion endpoint (PDF/TXT support)
Build embedding generation pipeline with batching
Set up Azure Cognitive Search index with metadata schema
Implement basic retrieval endpoint with k results parameter

Frontend Tasks:

Initialize Next.js project with App Router
Set up Tailwind + ShadCN UI component library
Create chat interface layout (header, message list, input)
Build message components (user/assistant, loading states)
Implement API client service with error handling
Add document upload UI with progress indication

Deliverables:

Working document upload and embedding
Basic Q&A functionality with citations
Simple chat interface with message history


Phase 2: Multi-Agent Routing
Goal: Implement agent orchestration with LangGraph
Backend Tasks:

Design LangGraph state schema (query, classification, chunks, response)
Implement Router Agent with classification prompt
Create agent communication protocol (shared state management)
Build orchestrator to manage agent handoffs
Add logging for agent transitions and decisions
Implement parallel execution where possible (retrieval + reasoning)

Frontend Tasks:

Add "Trace Mode" toggle in UI settings
Create agent activity visualization (step-by-step breakdown)
Display classification results (factual/counterfactual/temporal badge)
Show agent handoff timeline in context panel

Deliverables:

Router correctly classifies queries
Agents communicate via LangGraph state
UI shows basic agent activity traces


Phase 3: Simulation Mode
Goal: Enable counterfactual "what-if" reasoning
Backend Tasks:

Build Simulation Agent with parameter extraction logic
Implement safe Python REPL tool for calculations
Create simulation prompt templates (projection scenarios)
Add validation for numerical inputs
Generate comparison outputs (current vs simulated)

Frontend Tasks:

Design simulation results card (side-by-side comparison)
Add visual indicators for simulated values (badge/icon)
Create input form for adjusting simulation parameters
Display assumptions clearly in context panel

Deliverables:

Queries like "What if revenue grows 15%?" produce projections
UI shows current vs simulated comparison
Users can adjust parameters and re-run


Phase 4: Temporal Mode
Goal: Detect and visualize knowledge evolution
Backend Tasks:

Implement Temporal Agent with timestamp clustering
Build contradiction detection logic (semantic similarity + date gaps)
Create timeline generation for document evolution
Add confidence scoring for temporal conflicts
Flag outdated information with replacement suggestions

Frontend Tasks:

Build timeline scrubber component for date navigation
Display knowledge evolution cards (older â†’ newer)
Add conflict highlighting with toggle between versions
Create visual indicators for outdated information

Deliverables:

System detects conflicts in documents across time
UI shows timeline of policy/knowledge changes
Users can navigate document history visually


Phase 5: UI Polish & Production Readiness
Goal: Professional interface with performance optimization
Frontend Tasks:

Implement smooth typing animations for responses
Add skeleton loaders for all async operations
Create empty states with helpful prompts
Build settings panel (model selection, temperature, etc.)
Add keyboard shortcuts (Cmd+K for search, etc.)
Implement dark mode with system preference detection
Optimize bundle size and lazy loading

Backend Tasks:

Add rate limiting and request validation
Implement caching layer for repeated queries
Add comprehensive error messages with recovery suggestions
Create health check endpoint
Add request ID tracking for debugging
Optimize embedding batch sizes

Deliverables:

Polished, responsive UI matching modern chat applications
Sub-second response times for cached queries
Graceful error handling and recovery


Phase 6: Open Source Release
Goal: Package for community use
Repository Setup:

Comprehensive README with architecture diagram
.env.sample with all required Azure keys
Setup scripts (setup.sh for Unix, setup.bat for Windows)
Sample dataset for testing (public domain documents)
Docker Compose configuration for one-command deployment
CI/CD pipeline for testing

Documentation:

Architecture overview with agent flow diagrams
API documentation (FastAPI auto-generated + custom examples)
Deployment guide (local, Docker, cloud options)
Configuration reference (environment variables, model settings)
Troubleshooting guide (common issues, Azure setup)
Contributing guidelines

Deliverables:

Production-ready open-source repository
Demo video/GIF showing key features
Published documentation site


Key Implementation Notes
Agent Communication Pattern
python# LangGraph state schema example
class AgentState(TypedDict):
    query: str
    classification: str
    retrieved_chunks: List[Dict]
    reasoning: str
    simulation_result: Optional[Dict]
    temporal_analysis: Optional[Dict]
    final_response: str
Error Handling Strategy

Graceful degradation (fallback to basic RAG if agent fails)
User-friendly error messages (no raw stack traces)
Retry logic for transient Azure API failures
Logging for debugging without exposing sensitive data

Performance Targets

Query response: < 3 seconds (excluding LLM latency)
Document ingestion: < 5 seconds per MB
UI interaction: < 100ms (perceived responsiveness)
Concurrent users: Support at least 10 (local deployment)

Security Considerations

No authentication (local-only deployment)
Azure keys in .env (never committed)
Input validation on all API endpoints
Sanitize file uploads (type checking, size limits)
Safe Python execution (restricted imports, timeouts)

Success Criteria

User can upload documents and get accurate answers with citations
Counterfactual queries produce meaningful simulations
Temporal conflicts are detected and visualized
UI feels responsive and professional
Open-source repository is documented and ready for community use
System runs fully locally with only Azure OpenAI as external dependency

Development Workflow

Start with Phase 1, verify functionality before moving forward
Write code incrementally, test each component in isolation
Commit working code frequently with clear messages
Create reusable abstractions as patterns emerge
Refactor when duplication appears, not prematurely
Document complex logic inline
Keep the UI functional at every phase (no broken states)